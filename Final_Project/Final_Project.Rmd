---
title: "Final Project"
author: "Tasheena Narraidoo, Jeffrey Lancaster, Luke Haggerty"
date: "December 22, 2017"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
    df_print: kable
---




## Load all packages

We have used `tidyverse` and `lubridate` for data cleaning and manipulation and for basic EDA, `ggmap` for additional EDA and `nnet` for our model.

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=4.5, echo=FALSE}
library(tidyverse)
library(ggmap)
library(gridExtra)
library(ggExtra)
library(lubridate)
library(viridis)
library(nnet)
```



## Load data and perform data cleaning

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=4.5, echo=FALSE}
# Load Data
#load train data
# train <- read_csv("data/train.csv")
#load test data
# test <- read_csv("data/test.csv")
```

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=4.5, echo=FALSE}
# Data Cleaning


```


## EDA visualizations and tables

Note: If you had to illustrate using no modelling but only graphs and tables which
variables have the most predictive power, which would you include?

```{r, echo=FALSE}
# Status: Completed (Just need to upload latest version)
# Table with variable description
var_name <- c("1 ", " 2")
var_description <- c(" 3", "4 ")
tbl <- cbind(var_name,var_description)
colnames(tbl) <- c("Variable Name", "Variable Description")
tbl %>% knitr::kable(digits=4)
```

```{r, echo=FALSE}
# Checking our variables
# Status: Completed (Just need to upload latest version)

```

```{r, echo=FALSE}
# Overall distribution of crimes
# Status: Completed (Just need to upload latest version)

```

```{r, echo=FALSE}
# Distribution over time for the Top 5 crimes
# Status: Completed (Just need to upload latest version)

```

```{r, echo=FALSE}
# Crime distribution by Time
# Status: Completed (Just need to upload latest version)

```

```{r, echo=FALSE}
# Crime distribution by Day
# Status: Completed (Just need to upload latest version)

```

```{r, echo=FALSE}
# Crime distribution by Month
# Status: Completed (Just need to upload latest version)

```


* Perform a cross-validation on only the final/ultimate model used for your
submission.
* The "score" in question should be the same as used to compute the Kaggle
leaderboard. In other words, your estimated score should be roughly equal to the
score returned by Kaggle after your submission.

## Ultimate model

```{r, echo=FALSE}


```


## Crossvalidation of ultimate model

Note: Hardcode your crossvalidation here i.e. do not use built-in crossvalidation
options.

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=4.5, echo=FALSE}

```



## Create submission

Note: Output a CSV using `write_csv(DATAFRAME_NAME, path="data/SUBMISSION_NAME.csv")`
that is Kaggle submitable. This submission should return a Kaggle score that is
close to your crossvalidated score.



## Citations and references

Note: All citations and references must be included here.

*

*

*


## Supplementary materials

Note: Anything else you've tried that you'd like to include, but isn't essential to
the above, like other EDA's, other modeling approaches you've tried, etc. Please
set the R code chunk `eval=FALSE` here so that default is that R Markdown
doesn't run the code, but a user can flip this switch if they are curious.

```{r, eval=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=4.5, echo=FALSE}


```





